# 📡 11일차: 외부 API와 웹 스크래핑

> **학습 목표**: Playwright를 활용한 웹 스크래핑과 브라우저 풀 관리, 실시간 데이터 수집 시스템 구현

---

## 🎯 학습 목표

### 핵심 목표
- Playwright 기반 웹 스크래핑 시스템 구현
- 브라우저 풀 매니저를 통한 리소스 관리
- 실시간 모니터링과 데이터 추출 기법
- 대용량 크롤링을 위한 성능 최적화

### 실무 역량
- 실제 웹사이트의 동적 콘텐츠 수집
- 브라우저 인스턴스의 효율적 관리
- 에러 처리와 복구 메커니즘 설계
- 레이트 리미팅과 예의바른 크롤링

---

## 📚 이론 학습

### 1. 웹 스크래핑의 진화

#### 전통적 방식의 한계
```javascript
// 기존 방식 - 정적 HTML 파싱
const axios = require('axios');
const cheerio = require('cheerio');

async function oldWayScaping(url) {
  const response = await axios.get(url);
  const $ = cheerio.load(response.data);
  // 동적 콘텐츠는 수집 불가능
  return $('.content').text();
}
```

#### 현대적 접근법 - 브라우저 자동화
```typescript
// Playwright를 활용한 동적 콘텐츠 수집
const { chromium } = require('playwright');

async function modernScraping(url: string) {
  const browser = await chromium.launch();
  const page = await browser.newPage();
  
  await page.goto(url);
  await page.waitForSelector('.dynamic-content'); // 동적 로딩 대기
  
  const data = await page.evaluate(() => {
    // 브라우저 내부에서 JavaScript 실행
    return document.querySelector('.dynamic-content')?.textContent;
  });
  
  await browser.close();
  return data;
}
```

### 2. 브라우저 풀 매니저의 필요성

#### 리소스 관리 문제
- **메모리 사용량**: 각 브라우저 인스턴스는 100-200MB 사용
- **시작 시간**: 브라우저 초기화에 2-5초 소요
- **동시성 제한**: OS별 프로세스 수 제한

#### 풀링 패턴의 장점
```typescript
// 브라우저 풀 매니저 개념
interface BrowserPool {
  getAvailableInstance(): BrowserInstance;
  releaseInstance(instance: BrowserInstance): void;
  adjustPoolSize(requiredSize: number): Promise<void>;
}
```

---

## 🔍 코드 분석

### 1. BrowserPoolManager 아키텍처

#### 핵심 인터페이스 정의
```typescript
export interface BrowserInstance {
  id: string;                    // 고유 식별자
  browser: Browser;             // Playwright Browser 인스턴스
  context: BrowserContext;      // 브라우저 컨텍스트
  isActive: boolean;           // 사용 중 여부
  assignedEntity?: string;     // 할당된 작업 식별자
  lastUsed: number;           // 마지막 사용 시간
  errorCount: number;         // 에러 발생 횟수
}

export interface PoolConfig {
  maxInstances: number;       // 최대 인스턴스 수
  minInstances: number;       // 최소 인스턴스 수
  entityType: 'cafe' | 'weverse';
  persistentDataPath: string; // 데이터 저장 경로
}
```

#### 동적 풀 조정 메커니즘
```typescript
/**
 * 필요한 브라우저 인스턴스 수 계산
 */
private async calculateRequiredInstances(): Promise<{ cafe: number; weverse: number }> {
  const cafeCount = await this.getActiveCafeStreamerCount();
  const weverseCount = await this.getActiveWeverseArtistCount();

  return {
    cafe: Math.min(Math.max(cafeCount, this.CONFIG.cafe.minInstances), this.CONFIG.cafe.maxInstances),
    weverse: Math.min(Math.max(weverseCount, this.CONFIG.weverse.minInstances), this.CONFIG.weverse.maxInstances)
  };
}

/**
 * 브라우저 풀 동적 조정
 */
async adjustBrowserPools(): Promise<void> {
  if (this.poolAdjustmentInProgress) {
    console.log('⏳ Browser pool adjustment already in progress, skipping...');
    return;
  }

  this.poolAdjustmentInProgress = true;
  
  try {
    const required = await this.calculateRequiredInstances();
    
    console.log(`📊 Required browser instances - Cafe: ${required.cafe}, Weverse: ${required.weverse}`);
    console.log(`📊 Current browser instances - Cafe: ${this.cafeBrowsers.length}, Weverse: ${this.weverseBrowsers.length}`);

    // 카페 브라우저 풀 조정
    await this.adjustPool('cafe', required.cafe);
    
    // 위버스 브라우저 풀 조정
    await this.adjustPool('weverse', required.weverse);

    console.log(`✅ Browser pool adjustment completed - Cafe: ${this.cafeBrowsers.length}, Weverse: ${this.weverseBrowsers.length}`);
    
  } catch (error) {
    console.error('❌ Failed to adjust browser pools:', error);
  } finally {
    this.poolAdjustmentInProgress = false;
  }
}
```

### 2. 브라우저 인스턴스 생성과 관리

#### 최적화된 브라우저 설정
```typescript
private async createBrowserInstance(platform: 'cafe' | 'weverse'): Promise<BrowserInstance> {
  const config = this.CONFIG[platform];
  const instanceId = `${platform}_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  
  try {
    console.log(`🚀 Creating ${platform} browser instance: ${instanceId}`);

    const browser = await chromium.launch({
      headless: true,
      args: [
        '--no-sandbox',                    // 샌드박스 비활성화
        '--disable-setuid-sandbox',
        '--disable-dev-shm-usage',         // /dev/shm 사용 비활성화
        '--disable-accelerated-2d-canvas', // 2D 캔버스 가속 비활성화
        '--no-first-run',                  // 첫 실행 설정 스킵
        '--no-zygote',                     // Zygote 프로세스 비활성화
        '--disable-gpu',                   // GPU 사용 비활성화
        '--disable-web-security',          // 웹 보안 비활성화
        '--disable-features=VizDisplayCompositor' // 디스플레이 컴포지터 비활성화
      ]
    });

    const context = await browser.newContext({
      userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
      viewport: { width: 1920, height: 1080 }
    });

    // 자동화 감지 방지
    await context.addInitScript(() => {
      Object.defineProperty(navigator, 'webdriver', {
        get: () => undefined,
      });
      delete (navigator as any).__proto__.webdriver;
    });

    const browserInstance: BrowserInstance = {
      id: instanceId,
      browser,
      context,
      isActive: false,
      lastUsed: Date.now(),
      errorCount: 0
    };

    console.log(`✅ ${platform} browser instance created: ${instanceId}`);
    return browserInstance;

  } catch (error) {
    console.error(`❌ Failed to create ${platform} browser instance:`, error);
    throw error;
  }
}
```

#### 라운드 로빈 인스턴스 할당
```typescript
/**
 * 사용 가능한 브라우저 인스턴스 가져오기 (라운드 로빈)
 */
getAvailableBrowserInstance(platform: 'cafe' | 'weverse'): BrowserInstance | null {
  const pool = platform === 'cafe' ? this.cafeBrowsers : this.weverseBrowsers;
  
  // 사용 중이 아닌 브라우저 중에서 가장 오래 사용되지 않은 것 선택
  const availableInstances = pool
    .filter(instance => !instance.isActive)
    .sort((a, b) => a.lastUsed - b.lastUsed);

  if (availableInstances.length > 0) {
    const instance = availableInstances[0];
    instance.isActive = true;
    instance.lastUsed = Date.now();
    return instance;
  }

  return null;
}

/**
 * 브라우저 인스턴스 사용 완료 처리
 */
releaseBrowserInstance(instanceId: string): void {
  const allInstances = [...this.cafeBrowsers, ...this.weverseBrowsers];
  const instance = allInstances.find(inst => inst.id === instanceId);
  
  if (instance) {
    instance.isActive = false;
    instance.lastUsed = Date.now();
  }
}
```

### 3. WeiverseMonitor의 고급 기법

#### 쿠키 우선순위 관리
```typescript
// 쿠키 관리 상수 정의
private static readonly CRITICAL_COOKIES = {
  // 최고 우선순위 - 인증 토큰
  HIGH_PRIORITY: [
    'we2_access_token',
    'we2_refresh_token',
    'access_token',
    'refresh_token'
  ],
  // 중간 우선순위 - 세션 관리
  MEDIUM_PRIORITY: [
    'weverse_session',
    'session_id',
    'auth_token',
    'JSESSIONID'
  ],
  // 낮은 우선순위 - 사용자 설정
  LOW_PRIORITY: [
    'user_id',
    'user_settings',
    'locale',
    'timezone'
  ]
};
```

#### 세션 무결성 검증
```typescript
private async validateSessionIntegrity(): Promise<boolean> {
  if (!this.context) return false;
  
  try {
    // 현재 쿠키 상태 확인
    const cookies = await this.context.cookies();
    const criticalCookies = cookies.filter(cookie => 
      WeiverseMonitor.CRITICAL_COOKIES.HIGH_PRIORITY.includes(cookie.name)
    );
    
    if (criticalCookies.length === 0) {
      console.log('❌ 중요 인증 쿠키 없음 - 세션 무결성 실패');
      return false;
    }
    
    // 만료된 쿠키 확인
    const now = Date.now() / 1000;
    const expiredCookies = criticalCookies.filter(cookie => 
      cookie.expires && cookie.expires < now
    );
    
    if (expiredCookies.length > 0) {
      console.log(`❌ ${expiredCookies.length}개 만료된 쿠키 발견 - 세션 무결성 실패`);
      return false;
    }
    
    console.log(`✅ 세션 무결성 검증 성공: ${criticalCookies.length}개 유효한 인증 쿠키`);
    return true;
    
  } catch (error) {
    console.error('세션 무결성 검증 실패:', error);
    return false;
  }
}
```

#### 위버스 ID 추출 로직
```typescript
/**
 * 위버스 URL에서 고유한 ID를 추출하는 함수
 */
private extractWeverseId(url: string): string {
  console.log(`[EXTRACT_ID] 🔍 Extracting Weverse ID from URL: ${url}`);
  
  // 위버스 Live URL 형식: /live/2-161749779 또는 /live/2-161749779?params
  const liveMatch = url.match(/\/live\/([^?#]+)/);
  if (liveMatch) {
    console.log(`[EXTRACT_ID] ✅ Found Live ID: ${liveMatch[1]}`);
    return liveMatch[1];
  }
  
  // 위버스 일반 게시물 URL 형식: /artist/2-161749779 또는 /moment/2-161749779
  const postMatch = url.match(/\/(?:artist|moment|media)\/([^?#]+)/);
  if (postMatch) {
    console.log(`[EXTRACT_ID] ✅ Found Post ID: ${postMatch[1]}`);
    return postMatch[1];
  }
  
  // 위버스 아티스트 페이지 URL 형식: /artistname/live/2-161749779
  const artistLiveMatch = url.match(/\/[^/]+\/live\/([^?#]+)/);
  if (artistLiveMatch) {
    console.log(`[EXTRACT_ID] ✅ Found Artist Live ID: ${artistLiveMatch[1]}`);
    return artistLiveMatch[1];
  }
  
  // 위버스 아티스트 게시물 URL 형식: /artistname/artist/2-161749779
  const artistPostMatch = url.match(/\/[^/]+\/(?:artist|moment|media)\/([^?#]+)/);
  if (artistPostMatch) {
    console.log(`[EXTRACT_ID] ✅ Found Artist Post ID: ${artistPostMatch[1]}`);
    return artistPostMatch[1];
  }
  
  // 기존 방식 (숫자만 추출) - 백워드 호환성
  const numericMatch = url.match(/\/(\d+)(?:[?#]|$)/);
  if (numericMatch) {
    console.log(`[EXTRACT_ID] ✅ Found Numeric ID: ${numericMatch[1]}`);
    return numericMatch[1];
  }
  
  // 모든 패턴이 실패하면 URL 해시 사용 (타임스탬프 대신)
  const urlHash = crypto.createHash('md5').update(url).digest('hex').substring(0, 8);
  console.log(`[EXTRACT_ID] ⚠️ No ID pattern matched, using URL hash: ${urlHash}`);
  return urlHash;
}
```

---

## 🛠️ 실습 예제

### 1. 기본 브라우저 풀 구현

#### Step 1: 브라우저 인스턴스 인터페이스 정의
```typescript
// src/main/services/BrowserInstance.ts
interface SimpleBrowserInstance {
  id: string;
  browser: Browser;
  page: Page;
  isActive: boolean;
  createdAt: number;
  errorCount: number;
}

class SimpleBrowserPool {
  private instances: SimpleBrowserInstance[] = [];
  private maxInstances: number = 3;
  
  constructor(maxInstances: number = 3) {
    this.maxInstances = maxInstances;
  }
  
  async getAvailableInstance(): Promise<SimpleBrowserInstance> {
    // 사용 가능한 인스턴스 찾기
    let instance = this.instances.find(inst => !inst.isActive);
    
    if (!instance) {
      if (this.instances.length < this.maxInstances) {
        // 새 인스턴스 생성
        instance = await this.createInstance();
        this.instances.push(instance);
      } else {
        // 가장 오래된 인스턴스 재사용
        instance = this.instances.sort((a, b) => a.createdAt - b.createdAt)[0];
        await this.resetInstance(instance);
      }
    }
    
    instance.isActive = true;
    return instance;
  }
  
  private async createInstance(): Promise<SimpleBrowserInstance> {
    const browser = await chromium.launch({ headless: true });
    const page = await browser.newPage();
    
    return {
      id: `browser_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      browser,
      page,
      isActive: false,
      createdAt: Date.now(),
      errorCount: 0
    };
  }
  
  private async resetInstance(instance: SimpleBrowserInstance): Promise<void> {
    try {
      await instance.page.close();
      instance.page = await instance.browser.newPage();
      instance.errorCount = 0;
    } catch (error) {
      console.error('Failed to reset browser instance:', error);
      instance.errorCount++;
    }
  }
  
  releaseInstance(instanceId: string): void {
    const instance = this.instances.find(inst => inst.id === instanceId);
    if (instance) {
      instance.isActive = false;
    }
  }
  
  async cleanup(): Promise<void> {
    for (const instance of this.instances) {
      try {
        await instance.browser.close();
      } catch (error) {
        console.error('Failed to close browser instance:', error);
      }
    }
    this.instances = [];
  }
}
```

#### Step 2: 브라우저 풀 활용 예제
```typescript
// src/main/services/WebScrapingService.ts
class WebScrapingService {
  private browserPool: SimpleBrowserPool;
  
  constructor() {
    this.browserPool = new SimpleBrowserPool(5);
  }
  
  async scrapeData(url: string): Promise<string> {
    const instance = await this.browserPool.getAvailableInstance();
    
    try {
      await instance.page.goto(url);
      await instance.page.waitForSelector('body');
      
      const data = await instance.page.evaluate(() => {
        // 페이지에서 데이터 추출
        const title = document.querySelector('h1')?.textContent;
        const content = document.querySelector('.content')?.textContent;
        
        return JSON.stringify({
          title: title || '',
          content: content || '',
          timestamp: Date.now()
        });
      });
      
      return data;
      
    } catch (error) {
      console.error('Scraping failed:', error);
      throw error;
    } finally {
      this.browserPool.releaseInstance(instance.id);
    }
  }
}

// 사용 예제
const scraper = new WebScrapingService();

async function main() {
  try {
    const data = await scraper.scrapeData('https://example.com');
    console.log('Scraped data:', data);
  } catch (error) {
    console.error('Error:', error);
  }
}
```

### 2. 동적 콘텐츠 수집 시스템

#### Step 1: 동적 로딩 대기 패턴
```typescript
// src/main/services/DynamicScraper.ts
class DynamicContentScraper {
  async scrapeWithWait(page: Page, url: string): Promise<any> {
    await page.goto(url, { waitUntil: 'networkidle' });
    
    // 방법 1: 특정 요소가 나타날 때까지 대기
    await page.waitForSelector('.dynamic-content', { timeout: 10000 });
    
    // 방법 2: JavaScript 실행 완료까지 대기
    await page.waitForFunction(() => {
      return window.document.readyState === 'complete';
    });
    
    // 방법 3: 특정 조건이 충족될 때까지 대기
    await page.waitForFunction(() => {
      const elements = document.querySelectorAll('.item');
      return elements.length > 0;
    });
    
    // 데이터 추출
    const data = await page.evaluate(() => {
      const items = Array.from(document.querySelectorAll('.item'));
      return items.map(item => ({
        title: item.querySelector('.title')?.textContent,
        content: item.querySelector('.content')?.textContent,
        timestamp: item.getAttribute('data-timestamp')
      }));
    });
    
    return data;
  }
}
```

#### Step 2: 무한 스크롤 처리
```typescript
async function scrapeInfiniteScroll(page: Page): Promise<any[]> {
  const allData: any[] = [];
  let previousHeight = 0;
  let currentHeight = await page.evaluate(() => document.body.scrollHeight);
  
  while (previousHeight !== currentHeight) {
    previousHeight = currentHeight;
    
    // 페이지 하단으로 스크롤
    await page.evaluate(() => {
      window.scrollTo(0, document.body.scrollHeight);
    });
    
    // 새 콘텐츠 로딩 대기
    await page.waitForTimeout(2000);
    
    // 현재 보이는 항목들 수집
    const newItems = await page.evaluate(() => {
      const items = Array.from(document.querySelectorAll('.new-item'));
      return items.map(item => ({
        id: item.getAttribute('data-id'),
        content: item.textContent
      }));
    });
    
    allData.push(...newItems);
    
    // 새로운 높이 확인
    currentHeight = await page.evaluate(() => document.body.scrollHeight);
    
    // 안전 장치: 최대 10번 스크롤
    if (allData.length > 1000) break;
  }
  
  return allData;
}
```

### 3. 에러 처리와 복구 메커니즘

#### Step 1: 재시도 패턴
```typescript
class RobustScraper {
  async scrapeWithRetry(
    url: string,
    maxRetries: number = 3,
    delayMs: number = 1000
  ): Promise<any> {
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        console.log(`Scraping attempt ${attempt}/${maxRetries}`);
        
        const result = await this.performScraping(url);
        console.log(`✅ Scraping succeeded on attempt ${attempt}`);
        return result;
        
      } catch (error) {
        console.error(`❌ Scraping failed on attempt ${attempt}:`, error);
        
        if (attempt === maxRetries) {
          throw new Error(`스크래핑 실패: ${maxRetries}번 시도 후 포기`);
        }
        
        // 지수 백오프 적용
        const delay = delayMs * Math.pow(2, attempt - 1);
        console.log(`⏳ ${delay}ms 대기 후 재시도...`);
        await this.delay(delay);
      }
    }
  }
  
  private async performScraping(url: string): Promise<any> {
    const instance = await this.browserPool.getAvailableInstance();
    
    try {
      // 타임아웃 설정
      instance.page.setDefaultTimeout(15000);
      
      await instance.page.goto(url);
      
      // 페이지 로딩 확인
      await instance.page.waitForLoadState('networkidle');
      
      // 데이터 추출
      const data = await instance.page.evaluate(() => {
        // 실제 스크래핑 로직
        return { success: true, data: '수집된 데이터' };
      });
      
      return data;
      
    } finally {
      this.browserPool.releaseInstance(instance.id);
    }
  }
  
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
```

#### Step 2: 서킷 브레이커 패턴
```typescript
class CircuitBreaker {
  private failures: number = 0;
  private lastFailureTime: number = 0;
  private state: 'closed' | 'open' | 'half-open' = 'closed';
  
  constructor(
    private threshold: number = 5,
    private timeoutMs: number = 60000
  ) {}
  
  async execute<T>(fn: () => Promise<T>): Promise<T> {
    if (this.state === 'open') {
      if (Date.now() - this.lastFailureTime > this.timeoutMs) {
        this.state = 'half-open';
        console.log('🔄 Circuit breaker: half-open 상태로 전환');
      } else {
        throw new Error('Circuit breaker is open');
      }
    }
    
    try {
      const result = await fn();
      
      if (this.state === 'half-open') {
        this.state = 'closed';
        this.failures = 0;
        console.log('✅ Circuit breaker: closed 상태로 복구');
      }
      
      return result;
      
    } catch (error) {
      this.failures++;
      this.lastFailureTime = Date.now();
      
      if (this.failures >= this.threshold) {
        this.state = 'open';
        console.log(`❌ Circuit breaker: open 상태로 전환 (${this.failures} 실패)`);
      }
      
      throw error;
    }
  }
}
```

---

## 📋 과제

### 📝 기본 과제
1. **브라우저 풀 구현**: 최대 3개 인스턴스를 관리하는 브라우저 풀 클래스 구현
2. **동적 콘텐츠 수집**: JavaScript로 동적 생성되는 콘텐츠를 수집하는 스크래퍼 구현
3. **에러 처리**: 재시도 로직과 타임아웃 처리가 포함된 견고한 스크래핑 시스템 구현

### 🚀 응용 과제
1. **레이트 리미팅**: 요청 간격을 자동 조절하는 스크래핑 시스템 구현
2. **세션 관리**: 로그인이 필요한 사이트의 세션을 유지하는 모니터링 시스템 구현
3. **병렬 처리**: 여러 페이지를 동시에 모니터링하는 시스템 구현

### 💪 도전 과제
1. **지능형 풀 관리**: 사용 패턴을 분석하여 풀 크기를 동적 조절하는 시스템 구현
2. **프록시 로테이션**: 여러 프록시를 순환 사용하는 고급 스크래핑 시스템 구현
3. **분산 모니터링**: 여러 브라우저 인스턴스를 활용한 분산 모니터링 시스템 구현

---

## 📚 추가 학습 자료

### 📖 핵심 문서
- [Playwright 공식 문서](https://playwright.dev/)
- [Browser Pool Pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/pool)
- [Web Scraping Best Practices](https://blog.apify.com/web-scraping-best-practices/)

### 🛠️ 실습 리소스
- [Playwright Examples](https://github.com/microsoft/playwright/tree/main/examples)
- [Anti-detection Techniques](https://github.com/berstend/puppeteer-extra/tree/master/packages/puppeteer-extra-plugin-stealth)
- [Crawling Ethics Guidelines](https://blog.apify.com/web-scraping-ethics/)

### 🎯 확장 학습
- **Cluster 모드**: 여러 프로세스에서 브라우저 풀 공유
- **Redis 기반 큐**: 스크래핑 작업을 큐로 관리
- **모니터링 대시보드**: 스크래핑 상태를 실시간 모니터링

---

## 💡 핵심 정리

### ✅ 학습 완료 체크리스트
- [ ] 브라우저 풀 매니저의 동작 원리 이해
- [ ] 동적 콘텐츠 수집 기법 습득
- [ ] 에러 처리와 복구 메커니즘 구현
- [ ] 성능 최적화 기법 적용
- [ ] 예의바른 크롤링 원칙 이해

### 🎯 다음 단계 미리보기
**12일차**에서는 이렇게 구축한 웹 스크래핑 시스템을 활용하여 **실시간 모니터링 시스템**을 구현하고, 이벤트 기반 아키텍처와 성능 최적화에 대해 심도있게 학습합니다.

---

*🚀 실제 프로덕션 환경에서 사용되는 브라우저 풀 관리와 웹 스크래핑 기법을 마스터했습니다! 이제 대용량 실시간 모니터링 시스템을 구축할 준비가 되었습니다.*